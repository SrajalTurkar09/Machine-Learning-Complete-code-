{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOCj6eLMp33E"
      },
      "source": [
        "# Implementing Ensemble Methods in Python\n",
        "1. Bagging Example (Random Forest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmGG77xJpzex",
        "outputId": "3f1e65fd-8e70-4dc5-efeb-1a799fe8cecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Random Forest Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSyf2M5hqLeN"
      },
      "source": [
        "# 2. Boosting Example (AdaBoost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDgzQUNSqB6b",
        "outputId": "4562998b-0a5f-495d-898b-8c024c6e486b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Rishu\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base classifier (Decision Tree)\n",
        "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# Initialize AdaBoost classifier\n",
        "adaboost_classifier = AdaBoostClassifier(base_estimator=base_classifier, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = adaboost_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"AdaBoost Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfGZ3wjcqlDu"
      },
      "source": [
        "# 3. Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1lRdGvdqOcQ",
        "outputId": "74adeb57-c217-48e7-a7db-c6c23452562a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stacked Model Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base models\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train base models\n",
        "rf_model.fit(X_train, y_train)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions from base models\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "\n",
        "# Stack predictions for meta-learner\n",
        "stacked_predictions = np.column_stack((rf_pred, gb_pred))\n",
        "\n",
        "# Initialize meta-learner (Logistic Regression)\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# Train meta-learner on stacked predictions\n",
        "meta_learner.fit(stacked_predictions, y_test)\n",
        "\n",
        "# Make final predictions using the stacked model\n",
        "stacked_pred = meta_learner.predict(stacked_predictions)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, stacked_pred)\n",
        "print(f\"Stacked Model Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G84U33VNq419"
      },
      "source": [
        "#4. Generalization Bounds and VC Dimension in Ensemble Methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz_eiJVsrGFy"
      },
      "source": [
        "# Hereâ€™s a practical example using cross-validation to estimate generalization performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmEUCaFuqouD",
        "outputId": "f0b8177f-7185-4d92-f489-65ef5c325f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Cross-Validation Accuracy: 0.9666666666666668\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Evaluate model using cross-validation\n",
        "cv_scores = cross_val_score(rf_classifier, X, y, cv=5)  # 5-fold cross-validation\n",
        "average_accuracy = cv_scores.mean()\n",
        "\n",
        "print(f\"Average Cross-Validation Accuracy: {average_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXnp34qMrNaL"
      },
      "source": [
        "# VC Dimension\n",
        "The VC dimension is a measure of the model's capacity to fit various functions and generalize to new data. You can experiment with different ensemble configurations and analyze their impact on model complexity and generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F0t1HeXq9J3",
        "outputId": "e541d499-9724-41e9-e036-14df202e0bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 1.0\n",
            "Estimated VC Dimension: 13.813781191217037\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Random Forest Accuracy: {accuracy}\")\n",
        "\n",
        "# Calculate VC Dimension\n",
        "n_train = X_train.shape[0]\n",
        "vc_dimension = 2 * np.log2(n_train)  # For binary classification, adjust for multi-class\n",
        "print(f\"Estimated VC Dimension: {vc_dimension}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDrdWLXArhnh"
      },
      "source": [
        "# 5. Ensuring Diversity in Ensembles\n",
        "To ensure diversity among models in an ensemble, you can vary algorithms, training data subsets, and feature sets:\n",
        "\n",
        "Varying Algorithms Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsnDemJHrXej",
        "outputId": "7d159600-ccba-4c13-a4b7-e91e4cbff24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Accuracy with Diverse Models: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Rishu\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize diverse models\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "# Train models on different algorithms\n",
        "rf_model.fit(X_train, y_train)\n",
        "gb_model.fit(X_train, y_train)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "gb_pred = gb_model.predict(X_test)\n",
        "lr_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Combine predictions (e.g., voting or averaging)\n",
        "ensemble_pred = np.mean([rf_pred, gb_pred, lr_pred], axis=0)\n",
        "\n",
        "# Evaluate ensemble accuracy\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_pred)\n",
        "print(f\"Ensemble Accuracy with Diverse Models: {ensemble_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNm3I83Pr0ui"
      },
      "source": [
        "# Varying Training Data Subsets (Bagging Example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFgQvUcVrxL1",
        "outputId": "084682bd-9644-4bd4-c4f2-9cc5bba552ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bagging Classifier Accuracy: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Rishu\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base classifier (Decision Tree)\n",
        "base_classifier = DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "# Initialize Bagging classifier\n",
        "bagging_classifier = BaggingClassifier(base_estimator=base_classifier, n_estimators=50, max_samples=0.5, max_features=0.5, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bagging_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSseUphqsFEH"
      },
      "source": [
        "# Varying Feature Sets Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZFbrQ0VsCTe",
        "outputId": "3c500541-9a4a-482e-9b29-28f3208f71f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy with Petal Features: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vary feature sets (for example, using only petal features)\n",
        "X_train_petal = X_train[:, 2:]  # Use only petal length and width\n",
        "X_test_petal = X_test[:, 2:]\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on petal features\n",
        "rf_classifier.fit(X_train_petal, y_train)\n",
        "\n",
        "# Make predictions using petal features\n",
        "y_pred_petal = rf_classifier.predict(X_test_petal)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_petal = accuracy_score(y_test, y_pred_petal)\n",
        "print(f\"Random Forest Accuracy with Petal Features: {accuracy_petal}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRfUTKYPsKWK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
