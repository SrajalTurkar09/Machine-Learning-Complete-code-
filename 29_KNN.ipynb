{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  1. Implementing k-NN from Scratch\n"
      ],
      "metadata": {
        "id": "OU2Jh8qYVKE_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnUSwraLVI9M",
        "outputId": "8f558827-fc72-41dc-f264-c730bc044615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Function to calculate the Euclidean distance between two points\n",
        "def euclidean_distance(a, b):\n",
        "    return np.sqrt(np.sum((a - b) ** 2))\n",
        "\n",
        "# k-NN function to classify test points based on the k nearest neighbors\n",
        "def knn(X_train, y_train, X_test, k=3):\n",
        "    predictions = []  # List to store predictions for each test point\n",
        "\n",
        "    # Loop over each test point\n",
        "    for test_point in X_test:\n",
        "        # Calculate distance between test point and all training points\n",
        "        distances = [euclidean_distance(test_point, x) for x in X_train]\n",
        "\n",
        "        # Get the indices of the k nearest neighbors\n",
        "        k_indices = np.argsort(distances)[:k]\n",
        "\n",
        "        # Get the labels of the k nearest neighbors\n",
        "        k_nearest_labels = [y_train[i] for i in k_indices]\n",
        "\n",
        "        # Determine the most common label among the nearest neighbors\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "\n",
        "        # Add the predicted label to the list of predictions\n",
        "        predictions.append(most_common[0][0])\n",
        "\n",
        "    return np.array(predictions)  # Return the list of predictions as a numpy array\n",
        "\n",
        "# Example usage of the knn function:\n",
        "X_train = np.array([[1, 2], [2, 3], [3, 4], [5, 6]])  # Training features\n",
        "y_train = np.array([0, 0, 1, 1])  # Training labels\n",
        "X_test = np.array([[1, 1], [4, 4]])  # Test features\n",
        "\n",
        "# Call the knn function to get predictions for the test points\n",
        "predictions = knn(X_train, y_train, X_test, k=4)\n",
        "print(predictions)  # Output: array([0, 1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Optimizing with NumPy\n",
        "    Optimized Python Implementation:"
      ],
      "metadata": {
        "id": "t_cnaC8tVtwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized k-NN function using NumPy for distance calculation\n",
        "def knn_optimized(X_train, y_train, X_test, k=3):\n",
        "    predictions = []  # List to store predictions for each test point\n",
        "\n",
        "    # Loop over each test point\n",
        "    for test_point in X_test:\n",
        "        # Calculate the distance between the test point and all training points using NumPy\n",
        "        distances = np.linalg.norm(X_train - test_point, axis=1)\n",
        "\n",
        "        # Get the indices of the k nearest neighbors\n",
        "        k_indices = np.argsort(distances)[:k]\n",
        "\n",
        "        # Get the labels of the k nearest neighbors\n",
        "        k_nearest_labels = y_train[k_indices]\n",
        "\n",
        "        # Determine the most common label among the nearest neighbors\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "\n",
        "        # Add the predicted label to the list of predictions\n",
        "        predictions.append(most_common[0][0])\n",
        "\n",
        "    return np.array(predictions)  # Return the list of predictions as a numpy array\n"
      ],
      "metadata": {
        "id": "04UVuAh_VdmO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. k-NN with Scikit-Learn\n",
        "    Using KNeighborsClassifier and KNeighborsRegressor:"
      ],
      "metadata": {
        "id": "anLdkcAIWMbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Instantiate a k-NN classifier with k=3 and distance-based weighting\n",
        "classifier = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the model on the test data\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "\n",
        "# Example for regression with k-NN\n",
        "# Instantiate a k-NN regressor with k=3 and distance-based weighting\n",
        "regressor = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
        "\n",
        "# Fit the regressor to the training data\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test data\n",
        "predictions = regressor.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PNaWy7HWHpW",
        "outputId": "aea678aa-9b20-4f63-c1b0-79fccff62e79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Performance Evaluation\n",
        "    Metrics:\n",
        "           "
      ],
      "metadata": {
        "id": "XZqYQRubWeis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, cross_val_score\n",
        "\n",
        "# Generate and print the confusion matrix\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "\n",
        "# Generate and print the classification report with precision, recall, and F1-score\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "# Perform cross-validation to evaluate model performance\n",
        "scores = cross_val_score(classifier, X, y, cv=5)\n",
        "print(\"Cross-validation scores:\", scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "GKICeZhaWao-",
        "outputId": "93ca9ca9-5666-4dd5-e0aa-71f425496011"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'cross_val_score' from 'sklearn.metrics' (/usr/local/lib/python3.10/dist-packages/sklearn/metrics/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a108ed621963>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Generate and print the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'cross_val_score' from 'sklearn.metrics' (/usr/local/lib/python3.10/dist-packages/sklearn/metrics/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Hyperparameter Tuning\n",
        "    Grid Search and Random Search:\n",
        "\n"
      ],
      "metadata": {
        "id": "pCVd1zukWp3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# Define a parameter grid for GridSearchCV or RandomizedSearchCV\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7],  # Different values for k\n",
        "    'weights': ['uniform', 'distance'],  # Weighting options\n",
        "    'metric': ['euclidean', 'manhattan']  # Distance metrics\n",
        "}\n",
        "\n",
        "# Perform Grid Search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters (Grid Search):\", grid_search.best_params_)\n",
        "\n",
        "# Perform Random Search to find the best hyperparameters\n",
        "random_search = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_grid, cv=5, n_iter=10)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best parameters (Random Search):\", random_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syEOzXZGWki2",
        "outputId": "59a56cb8-e7ef-419f-d1d6-3cad0f900d18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters (Grid Search): {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
            "Best parameters (Random Search): {'weights': 'distance', 'n_neighbors': 5, 'metric': 'euclidean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing k-NN Regression in Scikit-Learn\n",
        "    Here's a basic implementation of k-NN regression using Scikit-Learn:"
      ],
      "metadata": {
        "id": "wpSfx0vgpYkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Generate a synthetic regression dataset\n",
        "X, y = make_regression(n_samples=500, n_features=2, noise=0.1, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the k-NN regressor with k=3\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=3)\n",
        "\n",
        "# Fit the model to the training data\n",
        "knn_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred = knn_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S60wfHinWykQ",
        "outputId": "749f115f-5dca-486c-eb77-cfbe38251963"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 1.0848932458375187\n",
            "Mean Squared Error (MSE): 2.9243728452646134\n",
            "Root Mean Squared Error (RMSE): 1.7100797774561902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faiss"
      ],
      "metadata": {
        "id": "6rxaFk-Dwf-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Generate a large dataset\n",
        "d = 64  # dimension\n",
        "nb = 1000000  # number of database vectors\n",
        "nq = 10000  # number of query vectors\n",
        "\n",
        "np.random.seed(1234)\n",
        "xb = np.random.random((nb, d)).astype('float32')\n",
        "xb[:, 0] += np.arange(nb) / 1000.\n",
        "xq = np.random.random((nq, d)).astype('float32')\n",
        "xq[:, 0] += np.arange(nq) / 1000.\n",
        "\n",
        "# Create index\n",
        "index = faiss.IndexFlatL2(d)  # L2 distance\n",
        "index.add(xb)  # add vectors to the index\n",
        "\n",
        "# Perform the search\n",
        "k = 5  # number of nearest neighbors\n",
        "D, I = index.search(xq, k)  # D stores distances, I stores indices of nearest neighbors\n",
        "print(I[:5])  # print the indices of the nearest neighbors for the first 5 queries\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUFuggL4plZf",
        "outputId": "444c2080-7951-4909-98ce-df9a6d86a81e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 774  175  917  413  365]\n",
            " [  98   66  357  596  969]\n",
            " [ 504  263  740  738   59]\n",
            " [ 756 1102  454  353 1136]\n",
            " [ 352  381  545  264   34]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1tOifNPbwmEw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}